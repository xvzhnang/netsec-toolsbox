# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ³¨å†Œè¡¨
å¯¹åº” One API çš„ model/channel.go + relay/adaptor.go
è´Ÿè´£ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼Œç®¡ç† Adapter å®ä¾‹
"""
import json
import os
import sys
import io
import traceback
from typing import Dict, Optional, List, Any
from pathlib import Path

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import sys
import os

# æ·»åŠ  ai_service ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.adapter.base_adapter import ChatAdapter
from core.adapter.openai_compat_adapter import OpenAICompatAdapter
# from .adapter.custom_http_adapter import CustomHTTPAdapter
# from .adapter.process_adapter import ProcessAdapter


class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œè¡¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹æ³¨å†Œè¡¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨æŸ¥æ‰¾
        """
        self.config_path = config_path or self._find_config_path()
        self.adapters: Dict[str, ChatAdapter] = {}
        self._load_models()
    
    def _find_config_path(self) -> str:
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶è·¯å¾„"""
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
        config_dir = os.environ.get('NETSEC_TOOLBOX_CONFIG_DIR')
        if config_dir:
            config_path = os.path.join(config_dir, 'models.json')
            if os.path.exists(config_path):
                return config_path
        
        # å°è¯•å¤šä¸ªä½ç½®
        possible_paths = [
            os.path.join(os.path.dirname(__file__), '..', 'config', 'models.json'),
            os.path.join(os.path.dirname(__file__), '..', 'models.json'),
            'models.json',
        ]
        
        if sys.platform == 'win32':
            appdata = os.environ.get('APPDATA', '')
            if appdata:
                possible_paths.insert(0, os.path.join(appdata, 'netsec-toolbox', '.config', 'models.json'))
        
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                return abs_path
        
        # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤è·¯å¾„
        return os.path.join(os.path.dirname(__file__), '..', 'config', 'models.json')
    
    def _load_models(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹"""
        if not os.path.exists(self.config_path):
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}ï¼Œå°è¯•åˆ›å»ºé»˜è®¤é…ç½®", flush=True)
            self._create_default_config()
            if not os.path.exists(self.config_path):
                print(f"âŒ æ— æ³•åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶ï¼Œæ¨¡å‹åŠ è½½å¤±è´¥", flush=True)
                return
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            models = config.get('models', [])
            
            for model_config in models:
                model_id = model_config.get('id')
                if not model_id:
                    print(f"âš ï¸ æ¨¡å‹é…ç½®ç¼ºå°‘ 'id' å­—æ®µï¼Œè·³è¿‡", flush=True)
                    continue
                
                adapter_type = model_config.get('adapter', 'openai_compat')
                enabled = model_config.get('enabled', True)
                
                if not enabled:
                    print(f"â„¹ï¸ æ¨¡å‹ {model_id} å·²ç¦ç”¨ï¼Œè·³è¿‡", flush=True)
                    continue
                
                try:
                    adapter = self._create_adapter(adapter_type, model_config)
                    if adapter and adapter.is_available():
                        self.adapters[model_id] = adapter
                        print(f"âœ… æ¨¡å‹ {model_id} ({adapter_type}) å·²åŠ è½½", flush=True)
                    else:
                        print(f"âš ï¸ æ¨¡å‹ {model_id} ({adapter_type}) ä¸å¯ç”¨ï¼Œè·³è¿‡", flush=True)
                except Exception as e:
                    print(f"âŒ åˆå§‹åŒ–æ¨¡å‹ {model_id} å¤±è´¥: {e}", file=sys.stderr, flush=True)
                    if config.get('debug', False):
                        traceback.print_exc(file=sys.stderr)
        
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr, flush=True)
            traceback.print_exc(file=sys.stderr)
    
    def _create_adapter(self, adapter_type: str, config: Dict) -> Optional[ChatAdapter]:
        """
        åˆ›å»ºé€‚é…å™¨å®ä¾‹
        å¯¹åº” One API çš„ relay.GetAdaptor
        """
        try:
            if adapter_type == 'openai_compat':
                return OpenAICompatAdapter(config)
            # elif adapter_type == 'custom_http':
            #     return CustomHTTPAdapter(config)
            # elif adapter_type == 'process':
            #     return ProcessAdapter(config)
            else:
                print(f"âš ï¸ æœªçŸ¥çš„é€‚é…å™¨ç±»å‹: {adapter_type}", flush=True)
                return None
        except Exception as e:
            print(f"âŒ åˆ›å»ºé€‚é…å™¨å¤±è´¥: {e}", file=sys.stderr, flush=True)
            traceback.print_exc(file=sys.stderr)
            return None
    
    def _create_default_config(self):
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        default_config = {
            "models": [
                {
                    "id": "gpt-3.5-turbo",
                    "adapter": "openai_compat",
                    "base_url": "https://api.openai.com/v1",
                    "api_key": "ENV:OPENAI_API_KEY",
                    "enabled": True,
                    "model": "gpt-3.5-turbo",
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "timeout": 60
                },
                {
                    "id": "deepseek-chat",
                    "adapter": "openai_compat",
                    "base_url": "https://api.deepseek.com/v1",
                    "api_key": "ENV:DEEPSEEK_API_KEY",
                    "enabled": True,
                    "model": "deepseek-chat",
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "timeout": 60
                }
            ]
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
        
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            print(f"âœ… å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {self.config_path}", flush=True)
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr, flush=True)
            traceback.print_exc(file=sys.stderr)
    
    def get_adapter(self, model_id: str) -> Optional[ChatAdapter]:
        """
        è·å–æŒ‡å®šæ¨¡å‹çš„é€‚é…å™¨
        å¯¹åº” One API çš„ CacheGetRandomSatisfiedChannelï¼ˆç®€åŒ–ç‰ˆï¼Œæ— è´Ÿè½½å‡è¡¡ï¼‰
        """
        return self.adapters.get(model_id)
    
    def list_models(self) -> Dict[str, Any]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
        ç”¨äº /v1/models æ¥å£
        """
        models_info = [adapter.get_model_info() for adapter in self.adapters.values()]
        return {
            "object": "list",
            "data": models_info
        }
    
    def reload(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        print("ğŸ”„ é‡æ–°åŠ è½½æ¨¡å‹é…ç½®...", flush=True)
        self.adapters.clear()
        self._load_models()

