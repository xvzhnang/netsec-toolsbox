# AI Gateway Service

基于 One API 架构思想的轻量级 AI Gateway 实现。

## 架构设计

```
models.json (配置)
    ↓
Registry (加载配置，创建 Adapter 实例)
    ↓
Router (根据 model_id 查找 Adapter)
    ↓
Adapter (发送请求，转换响应)
    ↓
OpenAI-compatible Response
```

## 目录结构

```
ai_service/
├── main_gateway.py          # 主服务入口
├── requirements.txt          # Python 依赖
├── core/
│   ├── adapter/
│   │   ├── base_adapter.py           # 适配器基类
│   │   └── openai_compat_adapter.py  # OpenAI 兼容适配器
│   ├── registry.py          # 模型注册表
│   └── router.py             # 请求路由器
├── api/
│   └── openai_handler.py     # OpenAI-compatible API Handler
└── config/
    └── models.json           # 模型配置文件
```

## 快速开始

### 1. 安装依赖

```bash
cd ai_service
python -m pip install -r requirements.txt
```

### 2. 配置模型

编辑 `config/models.json`，添加你的 API Key：

```json
{
  "models": [
    {
      "id": "gpt-3.5-turbo",
      "adapter": "openai_compat",
      "base_url": "https://api.openai.com/v1",
      "api_key": "ENV:OPENAI_API_KEY",
      "enabled": true,
      "model": "gpt-3.5-turbo"
    }
  ]
}
```

### 3. 启动服务

```bash
python main_gateway.py --port 8765
```

### 4. 测试

```bash
# 获取模型列表
curl http://127.0.0.1:8765/v1/models

# 发送聊天请求
curl http://127.0.0.1:8765/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## 配置说明

### 完整模型列表

AI Gateway 支持 One API 中所有已实现的 AI 模型，包括：

**OpenAI 兼容模型**（使用 `openai_compat` 适配器）：
- OpenAI (GPT-3.5, GPT-4, GPT-4 Turbo)
- DeepSeek (Chat, Coder)
- Groq
- Together AI
- Mistral AI
- Ollama (本地)
- LM Studio (本地)
- vLLM (本地)
- LocalAI (本地)
- Cloudflare Workers AI

**需要协议转换的模型**（使用 `custom_http` 适配器，待实现）：
- Anthropic Claude
- Google Gemini
- 智谱 AI (Zhipu)
- 百度文心一言
- 阿里通义千问
- 讯飞星火
- 腾讯混元
- Moonshot (Kimi)
- 百川智能
- MINIMAX
- 字节跳动豆包
- 零一万物
- 阶跃星辰
- Cohere
- Coze
- SiliconFlow
- xAI (Grok)
- Replicate
- DeepL
- Novita
- 360 智脑
- Google Vertex AI
- AWS Bedrock
- 阿里百炼

详细的模型配置和使用方法请参考 [MODELS_CONFIG_GUIDE.md](./MODELS_CONFIG_GUIDE.md)。

### models.json 格式

```json
{
  "models": [
    {
      "id": "模型ID（用于路由）",
      "adapter": "适配器类型（openai_compat / custom_http / process）",
      "base_url": "API 基础 URL",
      "api_key": "API Key（支持 ENV:VAR_NAME 环境变量）",
      "enabled": true,
      "model": "实际使用的模型名称",
      "temperature": 0.7,
      "max_tokens": 2000,
      "timeout": 60
    }
  ]
}
```

### 环境变量支持

API Key 支持环境变量引用：
- `"api_key": "ENV:OPENAI_API_KEY"` - 从环境变量 `OPENAI_API_KEY` 读取

## API 接口

### POST /v1/chat/completions

OpenAI-compatible 聊天接口。

**请求示例**：
```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "max_tokens": 2000
}
```

**响应格式**：标准 OpenAI Chat Completions 响应

### GET /v1/models

获取可用模型列表。

**响应示例**：
```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-3.5-turbo",
      "object": "model",
      "created": 0,
      "owned_by": "openai_compat"
    }
  ]
}
```

### GET /health

健康检查接口。

## 适配器类型

### openai_compat

适用于所有 OpenAI-compatible API：
- OpenAI
- DeepSeek
- Ollama
- vLLM
- LocalAI
- LM Studio
- Groq
- Together AI
- Mistral AI

### custom_http（待实现）

适用于需要协议转换的 API：
- Anthropic Claude
- Google Gemini
- 其他自定义 HTTP API

### process（待实现）

适用于本地 CLI 工具：
- llama.cpp
- 其他本地模型推理工具

## 与 One API 的对比

| 特性 | One API | AI Gateway |
|------|---------|------------|
| 接口 | OpenAI-compatible | ✅ 相同 |
| 配置存储 | 数据库 | ✅ JSON 文件 |
| 用户系统 | ✅ 完整 | ❌ 无 |
| 配额管理 | ✅ 完整 | ❌ 无 |
| Web 管理后台 | ✅ 完整 | ❌ 无 |
| 适配器抽象 | ✅ | ✅ 相同 |
| 复杂度 | 高 | 低 |

## 开发计划

- [x] OpenAI Compat 适配器
- [x] Registry 和 Router
- [x] API Handler
- [x] 完整的模型配置（基于 One API）
- [x] Custom HTTP 适配器（支持 Anthropic, Gemini, Zhipu, Baidu, Ali）
- [x] 更多转换器（腾讯、Moonshot、Minimax、Doubao）
- [x] Process 适配器（本地 CLI 工具）
- [x] 流式响应支持（SSE）
- [ ] 错误重试机制
- [ ] WebSocket 支持（讯飞星火等）

## 相关文档

- [模型配置指南](./MODELS_CONFIG_GUIDE.md) - 所有支持的模型及其配置方法
- [架构分析文档](../ONE_API_ARCHITECTURE_ANALYSIS.md) - One API 架构分析
- [实现指南](../AI_GATEWAY_IMPLEMENTATION_GUIDE.md) - 实现细节和代码示例

